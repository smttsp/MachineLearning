{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SECTION B: TF-IDF\n",
    "    This section is TF-IDF section that we want to get the distribution and frequency of each work in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import operator\n",
    "import heapq\n",
    "import sys\n",
    "\n",
    "#To do: Find all the words (corpus)\n",
    "# For each word, find their distribution in the documents (how many documents contain them) \n",
    "# for each document, find the frequency of the word in the document and calculate TF-IDF\n",
    "\n",
    "#LOAD YELP REVIEWS\n",
    "#FIND THE TF FOR ALL FILES WHILE LOADING\n",
    "\n",
    "def read_json(filename):\n",
    "    data = []\n",
    "    i = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for rev in f:\n",
    "            if i % 1000000==0:\n",
    "                print(i)\n",
    "            line = json.loads(rev)\n",
    "            data.append(line)\n",
    "            i+=1\n",
    "    return data\n",
    "\n",
    "# filename= 'C:\\\\Users\\\\Samet\\\\Dropbox\\\\courses\\\\machine learning\\\\yelp\\\\yelp_review.json';\n",
    "# data = read_json(filename)\n",
    "# print(len(data))\n",
    "# print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "645046\n",
      "2.237770918305159\n",
      "idf finito\n"
     ]
    }
   ],
   "source": [
    "#FIND THE Inverse Document Frequency(IDF) FOR EACH WORD\n",
    "def calc_idf(data):\n",
    "    N = len(data);\n",
    "    idf = dict()\n",
    "    i = 0\n",
    "    for row in data:\n",
    "        if i % 500000 == 0:\n",
    "            print(i)\n",
    "        i+=1;\n",
    "        \n",
    "        wc = tools.count_words(tools.make_text_parsable( row['text']))\n",
    "        for t in wc:\n",
    "            if t in idf:\n",
    "                idf[t] += 1  \n",
    "            else:\n",
    "                idf[t] = 1;\n",
    "    \n",
    "    for word in idf:\n",
    "        idf[word] = math.log(N/idf[word])\n",
    "    \n",
    "    return idf;\n",
    "\n",
    "idf = calc_idf(data)\n",
    "print(len(idf))\n",
    "print(idf['order'])\n",
    "print('idf finito')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "2685066\n"
     ]
    }
   ],
   "source": [
    "#LOAD YELP REVIEWS\n",
    "from collections import Counter\n",
    "\n",
    "def file2TF(data,idf):\n",
    "    wc = defaultdict(int)\n",
    "    i = 0;\n",
    "    rev_topic = []\n",
    "\n",
    "    for line in data:\n",
    "        if i % 1000000 == 0:\n",
    "            print(i)\n",
    "        i+=1;\n",
    "\n",
    "        d = dict()\n",
    "        wc = tools.count_words(tools.make_text_parsable( line['text']))\n",
    "        wc = sorted(wc.items(), key=lambda x: x[0]);\n",
    "\n",
    "        total = 0;\n",
    "        for c in wc:\n",
    "            total += c[1];\n",
    "        wcount = dict()\n",
    "        for cc in wc:\n",
    "            wcount[cc[0]] = cc[1]/total*idf[cc[0]];\n",
    "        \n",
    "        t5 = Counter(wcount).most_common(5)\n",
    "\n",
    "#         t5 = heapq.nlargest(5, wcount, key=wcount.get)\n",
    "\n",
    "        d['business_id'] = line['business_id'];\n",
    "        d['stars'] = line['stars'];\n",
    "        d['text'] = t5;\n",
    "        rev_topic.append(d)\n",
    "\n",
    "#         print(d)\n",
    "#         if i > 1:\n",
    "#             break;\n",
    "#         i+=1;\n",
    "        \n",
    "    return rev_topic;\n",
    "\n",
    "rev_topic = file2TF(data,idf)\n",
    "\n",
    "print(len(rev_topic))\n",
    "# print('tf finito')\n",
    "\n",
    "# print(rev_topic[0])\n",
    "# print(rev_topic[1])\n",
    "# print(rev_topic[2])\n",
    "\n",
    "# import json\n",
    "# with open('tf_idf_review2.json', 'w') as f:\n",
    "#     json.dump(rev_topic, f, ensure_ascii=False)\n",
    "\n",
    "# print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ##################------------------START FROM HERE-------------------------\n",
    "# import json\n",
    "# file= 'tf_idf_review.json';\n",
    "# rev_topic = []\n",
    "# i = 0\n",
    "# with open(file, 'r') as f:\n",
    "#     for rev in f:\n",
    "#         if i % 1000000==0:\n",
    "#             print(i)\n",
    "#         i+=1\n",
    "#         rev_topic.append(json.loads(rev))\n",
    "# rev_topic = rev_topic[0]\n",
    "\n",
    "# print(len(rev_topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "busn_rev:  85539\n",
      "85539\n",
      "{'neg_rev': {'74\\n\\nso': 0.4067594884549598, 'onions': 0.6750382494276584, 'dressing': 0.586648291648821, 'pasquales': 0.38771334367609744, 'failure': 0.339540557006086, 'pizza': 0.4265655149173117, 'hoagies': 0.9998839719666768, 'formed': 0.35214761861457927, 'bologna': 0.7642945337445709, 'subway': 0.32363289442740983, '\\n\\ncons': 0.2942919072671415, 'hoagie': 4.66536293404731}, 'business_id': '5UmKMjUEUNdYWqANhGckJw', 'pos_rev': {'pennysaver': 2.0174576983145664, 'pizza': 0.4265655149173117, 'superb': 2.38619055090495, 'hoggies': 2.1653364593457853, 'voted': 0.5095906894954388, 'awards': 1.219933579064674, 'piled': 1.0810139294600014, '\\n\\ncons': 0.2942919072671415, 'dated': 1.011580732886751, 'tradition': 3.067241393194274, '70s': 0.5136498615843546, 'poster': 0.9265402112224997, 'failure': 0.339540557006086, 'exploding': 1.0509000882629005, 'hoagie': 1.6179928903472791, 'machines': 2.3718549530717947, 'formed': 0.35214761861457927, 'mario': 3.3313308734672407, 'throwback': 0.5342985932048444, 'steeped': 4.316774263398974, 'badly': 0.7590052848822552, 'updated': 0.7030754968950038, 'speciality': 0.49589115914854787}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_max(tup):\n",
    "    m = -1;\n",
    "    for w in a:\n",
    "        if w[1] > m:\n",
    "            m = w[1]\n",
    "    return m;\n",
    "\n",
    "\n",
    "def find_busn_rev(busn_rev_pos):\n",
    "    busn_rev = []\n",
    "\n",
    "    cnt = 0\n",
    "#     busn_rev_pos = dict()\n",
    "    bpos = 0\n",
    "    for rev in rev_topic:\n",
    "        if rev['business_id'] in busn_rev_pos:\n",
    "            pos = busn_rev_pos[rev['business_id']];\n",
    "            busn = busn_rev[pos]\n",
    "        else:\n",
    "            busn_rev_pos[rev['business_id']] = bpos;\n",
    "            bpos += 1;\n",
    "            busn = dict()\n",
    "            busn['business_id'] = rev['business_id']\n",
    "            busn['pos_rev'] = dict()\n",
    "            busn['neg_rev'] = dict()\n",
    "            busn_rev.append(busn)\n",
    "            pos = bpos;\n",
    "\n",
    "    #     print(pos)\n",
    "    #     busn = busn_rev[pos];\n",
    "\n",
    "        if rev['stars'] > 3:\n",
    "            rtype = 'pos_rev'\n",
    "        elif rev['stars'] < 3:\n",
    "            rtype = 'neg_rev'\n",
    "    #     else:\n",
    "    #         rtype = 'avg_rev'\n",
    "        \n",
    "        mx = find_max(rev['text'])\n",
    "        \n",
    "        for txt in rev['text']:\n",
    "#             print('txt:', txt)\n",
    "#             print('type_txt: ', txt[0])\n",
    "            if rev['stars'] != 3:\n",
    "                if not txt[0] in busn[rtype]:\n",
    "                    busn[rtype][txt[0]] = math.fabs((rev['stars']-3)*txt[1])/mx\n",
    "                else:\n",
    "                    busn[rtype][txt[0]] += math.fabs((rev['stars']-3)*txt[1])/mx\n",
    "            else:\n",
    "                if not txt[0] in busn['neg_rev']:\n",
    "                    busn['neg_rev'][txt[0]] = 0.5*txt[1]/mx\n",
    "                else: \n",
    "                    busn['neg_rev'][txt[0]] += 0.5*txt[1]/mx\n",
    "                if not txt in busn['pos_rev']:\n",
    "                    busn['pos_rev'][txt[0]] = 0.5*txt[1]/mx\n",
    "                else: \n",
    "                    busn['pos_rev'][txt[0]] += 0.5*txt[1]/mx\n",
    "    #         busn_rev.append(busn)\n",
    "#         if cnt > 10:\n",
    "#             break\n",
    "\n",
    "        if cnt % 1000000 == 0:\n",
    "            print(cnt)\n",
    "        cnt+=1;\n",
    "    \n",
    "    return busn_rev; \n",
    "\n",
    "busn_rev_pos = dict();\n",
    "busn_rev = find_busn_rev(busn_rev_pos)\n",
    "\n",
    "print('busn_rev: ', len(busn_rev))\n",
    "print(len(busn_rev_pos))\n",
    "\n",
    "print(busn_rev[0], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# START FROM HERE -- WE HAVE BUSINESS SUMMARY OF TOP 5 WORDS IN EACH REVIEW FOR EACH BUSINESSES\n",
    "# import json\n",
    "# file = 'business_review.json';\n",
    "# busn_rev = []\n",
    "# i = 0\n",
    "# with open(file, 'r') as f:\n",
    "#     for rev in f:\n",
    "#         if i % 100==0:\n",
    "#             print(i)\n",
    "#         i+=1\n",
    "#         busn_rev.append(json.loads(rev))\n",
    "\n",
    "# busn_rev = busn_rev[0]\n",
    "\n",
    "# print(busn_rev[0])\n",
    "# print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file= 'C:\\\\Users\\\\Samet\\\\Dropbox\\\\courses\\\\machine learning\\\\yelp\\\\yelp_business.json';\n",
    "# business = []\n",
    "# i = 0\n",
    "# with open(file, 'r') as f:\n",
    "#     for rev in f:\n",
    "#         line = json.loads(rev)\n",
    "#         business.append(line)\n",
    "# print(len(business))\n",
    "# print(business[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017\n",
      "413\n",
      "413\n"
     ]
    }
   ],
   "source": [
    "# find all types of businesses \n",
    "def find_categories():\n",
    "\n",
    "    file= 'C:\\\\Users\\\\Samet\\\\Dropbox\\\\courses\\\\machine learning\\\\yelp\\\\yelp_business.json';\n",
    "    business = []\n",
    "    i = 0\n",
    "    with open(file, 'r') as f:\n",
    "        for rev in f:\n",
    "            line = json.loads(rev)\n",
    "            business.append(line)\n",
    "\n",
    "\n",
    "    tcategories = {}\n",
    "    for busn in business:\n",
    "        for bcat in busn['categories']:\n",
    "            if not bcat in tcategories:\n",
    "                tcategories[bcat] = []\n",
    "    #         print(busn['business_id'])\n",
    "            tcategories[bcat].append(busn['business_id'])\n",
    "    print(len(tcategories))\n",
    "    categories={}\n",
    "    for cat in tcategories:\n",
    "        if len(tcategories[cat]) > 50:\n",
    "            categories[cat] = tcategories[cat] \n",
    "    del tcategories\n",
    "    print(len(categories))\n",
    "    \n",
    "    return categories;\n",
    "categories = find_categories()\n",
    "print(len(categories))\n",
    "# print(categories['Fast Food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85539\n",
      "{'neg_rev': {'74\\n\\nso': 0.4067594884549598, 'onions': 0.6750382494276584, 'dressing': 0.586648291648821, 'pasquales': 0.38771334367609744, 'failure': 0.339540557006086, 'pizza': 0.4265655149173117, 'hoagies': 0.9998839719666768, 'formed': 0.35214761861457927, 'bologna': 0.7642945337445709, 'subway': 0.32363289442740983, '\\n\\ncons': 0.2942919072671415, 'hoagie': 4.66536293404731}, 'business_id': '5UmKMjUEUNdYWqANhGckJw', 'pos_rev': {'pennysaver': 2.0174576983145664, 'pizza': 0.4265655149173117, 'superb': 2.38619055090495, 'hoggies': 2.1653364593457853, 'voted': 0.5095906894954388, 'awards': 1.219933579064674, 'piled': 1.0810139294600014, '\\n\\ncons': 0.2942919072671415, 'dated': 1.011580732886751, 'tradition': 3.067241393194274, '70s': 0.5136498615843546, 'poster': 0.9265402112224997, 'failure': 0.339540557006086, 'exploding': 1.0509000882629005, 'hoagie': 1.6179928903472791, 'machines': 2.3718549530717947, 'formed': 0.35214761861457927, 'mario': 3.3313308734672407, 'throwback': 0.5342985932048444, 'steeped': 4.316774263398974, 'badly': 0.7590052848822552, 'updated': 0.7030754968950038, 'speciality': 0.49589115914854787}}\n"
     ]
    }
   ],
   "source": [
    "print(len(busn_rev))\n",
    "print(busn_rev[0])\n",
    "cnt = 0;\n",
    "busn_rev_pos = dict()\n",
    "for b in busn_rev:\n",
    "    busn_rev_pos[b['business_id']] = cnt;\n",
    "    cnt += 1;\n",
    "# print(busn_rev_pos['tJvUgjY7dJhCunOC10tKpg'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito\n",
      "{'neg_rev': [('bbq', 1221.58745123792), ('ribs', 715.7191432288653), ('brisket', 667.4028488410024), ('barbecue', 275.31926048213586), ('closed', 244.54334941011996), ('korean', 222.2949228306327), ('pulled', 197.99801667999284), ('pork', 188.4356436107668), ('dry', 176.92551567079335), ('meat', 176.67737996256287)], 'category': 'Barbeque', 'pos_rev': [('bbq', 2313.359145534801), ('ribs', 1251.0702258793117), ('brisket', 963.8360378873683), ('barbecue', 917.5069447881218), ('pulled', 831.3089035896062), ('pork', 638.4514956946668), ('awesome', 609.2399522151665), ('texas', 529.1785827595517), ('mac', 528.6867021912998), ('excellent', 467.207811062993)]}\n"
     ]
    }
   ],
   "source": [
    "# businesses     : information about each business\n",
    "# busn_rev       : reviews about each business\n",
    "# busn_rev_pos   : position of each business in busn_rev\n",
    "# categories     : different types of categories which is used in at least 50 different business, \n",
    "#                  it also include the businesses that use this category name in their tags\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "category_rev = [];\n",
    "i = 0;\n",
    "for cat in categories:\n",
    "    cpos_rev = dict()\n",
    "    cneg_rev = dict()\n",
    "    for busn in categories[cat]:\n",
    "        if busn in busn_rev_pos:\n",
    "            pos_rev = busn_rev[busn_rev_pos[busn]]['pos_rev']\n",
    "        if busn in busn_rev_pos:\n",
    "            neg_rev = busn_rev[busn_rev_pos[busn]]['neg_rev']\n",
    "        \n",
    "        for p in pos_rev:\n",
    "            if not p in cpos_rev:\n",
    "                cpos_rev[p] = pos_rev[p]\n",
    "            else:\n",
    "                cpos_rev[p] += pos_rev[p]\n",
    "                \n",
    "        for n in neg_rev:\n",
    "            if not n in cneg_rev:\n",
    "                cneg_rev[n] = neg_rev[n]\n",
    "            else:\n",
    "                cneg_rev[n] += neg_rev[n]\n",
    "\n",
    "#         print(pos_rev)\n",
    "#         print()\n",
    "#         print(cpos_rev)\n",
    "#         print('\\n')\n",
    "#         i+=1\n",
    "#         if i == 2:\n",
    "#             break\n",
    "    cp = Counter(cpos_rev).most_common(10)\n",
    "    cn = Counter(cneg_rev).most_common(10)\n",
    "#     print(cat)\n",
    "#     print(cp)\n",
    "#     print(cn)\n",
    "#     print(cneg_rev)\n",
    "    cr = dict()\n",
    "    cr['category'] = cat\n",
    "    cr['pos_rev'] = cp;\n",
    "    cr['neg_rev'] = cn;\n",
    "    category_rev.append(cr)\n",
    "#     break\n",
    "print('finito')\n",
    "print(category_rev[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('category_rev_normalized.json', 'w') as f:\n",
    "    json.dump(category_rev, f, ensure_ascii=False)\n",
    "print('finito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Management   [('property', 299.4245045846979), ('eloff', 217.0408473636617), ('realty', 175.83258798050036), ('management', 78.58800519104993), ('renton', 68.44823318211466), ('properties', 67.44178341868712), ('tenants', 60.701293321954985), ('estate', 58.60759761983811), ('xpand', 54.44705848665631), ('mckenna', 53.491290727705845)]   [('property', 180.2176905159547), ('company', 110.7514681319512), ('rent', 88.64256098517168), ('hoa', 82.45330065044793), ('deposit', 67.0826360086611), ('lease', 59.22050892294883), ('management', 53.56623850600867), ('tenant', 44.66952577939606), ('apartment', 40.126129340369665), ('community', 31.439682376189253)]\n"
     ]
    }
   ],
   "source": [
    "a = category_rev[12]\n",
    "print(a['category'], ' ', a['pos_rev'], ' ', a['neg_rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-368d9c008a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mrev_topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "del data\n",
    "del rev_topicopicopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "filename= 'C:\\\\Users\\\\Samet\\\\Jupyter\\\\class_activities\\\\ML_Project\\\\category_rev_normalized.json';\n",
    "data = read_json(filename)\n",
    "print(len(data))\n",
    "data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  Barbeque \n",
      "\n",
      "pos_rev:  [['bbq', 2313.359145534801], ['ribs', 1251.0702258793117], ['brisket', 963.8360378873683], ['barbecue', 917.5069447881218], ['pulled', 831.3089035896062], ['pork', 638.4514956946668], ['awesome', 609.2399522151665], ['texas', 529.1785827595517], ['mac', 528.6867021912998], ['excellent', 467.207811062993]] \n",
      "\n",
      "neg_rev:  [['bbq', 1221.58745123792], ['ribs', 715.7191432288653], ['brisket', 667.4028488410024], ['barbecue', 275.31926048213586], ['closed', 244.54334941011996], ['korean', 222.2949228306327], ['pulled', 197.99801667999284], ['pork', 188.4356436107668], ['dry', 176.92551567079335], ['meat', 176.67737996256287]]\n"
     ]
    }
   ],
   "source": [
    "print('category: ', data[0]['category'],'\\n')\n",
    "print('pos_rev: ', data[0]['pos_rev'],'\\n')\n",
    "print('neg_rev: ', data[0]['neg_rev'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "85539\n"
     ]
    }
   ],
   "source": [
    "filename= 'C:\\\\Users\\\\Samet\\\\Jupyter\\\\class_activities\\\\ML_Project\\\\business_review.json';\n",
    "busn_rev = read_json(filename)\n",
    "print(len(busn_rev))\n",
    "busn_rev = busn_rev[0]\n",
    "print(len(busn_rev))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_rev': [['pizza', 9951.977240103099], ['closed', 6513.160947312419], ['horrible', 5330.752482224191], ['sushi', 5175.801300781342], ['terrible', 5032.128887933889], ['burger', 4658.641884059828], ['we', 4537.315115379173], ['buffet', 3982.7534046315195], ['she', 3879.472129840654], ['worst', 3454.900564125713]], 'category': 'Restaurants', 'pos_rev': [['love', 13401.43197954094], ['excellent', 12901.329386456751], ['great', 12007.564751300903], ['awesome', 11928.436859915128], ['pizza', 11926.480224925355], ['amazing', 10673.585079497969], ['always', 9342.949484322025], ['yum', 8875.64276978918], ['yummy', 8404.29109215509], ['best', 8253.431838085946]]}\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    if i['category'] == 'Restaurants':\n",
    "        print(i)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['business_id'] = line['business_id'];\n",
    "d['stars'] = line['stars'];\n",
    "d['text'] = t5;\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
